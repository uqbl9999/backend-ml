{
  "cells": [
    {"cell_type": "markdown", "metadata": {}, "source": ["# AnÃ¡lisis Exploratorio, PreparaciÃ³n y ML (Colab Ready)"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\nIN_COLAB = 'google.colab' in sys.modules\nif IN_COLAB:\n    !pip -q install pandas numpy seaborn matplotlib scikit-learn scipy\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# (Opcional) Subir data/tamizajes.csv en Colab\nuploaded = {}\nif IN_COLAB:\n    from google.colab import files\n    print('Ejecuta: uploaded = files.upload() y selecciona data/tamizajes.csv')\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os, warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt, seaborn as sns\nsns.set_palette('husl'); plt.style.use('seaborn-v0_8-darkgrid')\ncolors=['#2E86AB','#E63946','#F18F01']\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## Cargar datos (sin limpiar) y EDA"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["candidates=['data/tamizajes.csv','tamizajes.csv']\nif 'uploaded' in globals() and isinstance(uploaded,dict) and len(uploaded): candidates=[list(uploaded.keys())[0]]+candidates\ndata_path=next((p for p in candidates if p and os.path.exists(p)), None)\nif not data_path: raise FileNotFoundError('Sube data/tamizajes.csv o ajusta la ruta')\nprint('Usando archivo:', data_path)\ndf=pd.read_csv(data_path, sep=';', encoding='latin1')\ndf.head()\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# GrÃ¡fico 1: DistribuciÃ³n por Grupo de Tamizaje\ngrupo_counts=df['GrupoTamizaje'].value_counts(); grupo_pct=(grupo_counts/len(df))*100\nplt.figure(figsize=(10,6)); bars=plt.bar(range(len(grupo_counts)), grupo_counts.values, color=colors[:len(grupo_counts)], alpha=0.8, edgecolor='black', linewidth=2)\nplt.xticks(range(len(grupo_counts)), grupo_counts.index, rotation=25, ha='right', fontsize=11); plt.ylabel('NÃºmero de Registros', fontsize=12)\nplt.title('DistribuciÃ³n de Registros por Grupo de Tamizaje', fontsize=14, fontweight='bold', pad=15); plt.grid(axis='y', alpha=0.3)\nfor i,b in enumerate(bars): h=b.get_height(); plt.text(b.get_x()+b.get_width()/2, h+(h*0.01), f'{grupo_counts.iloc[i]:,}\\n({grupo_pct.iloc[i]:.1f}%)', ha='center', va='bottom', fontsize=10, fontweight='bold')\nplt.tight_layout(); plt.savefig('EDA_01_distribucion_grupo_tamizaje.png', dpi=300, bbox_inches='tight'); plt.show()\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# GrÃ¡fico 2: Suma Total de Casos por Grupo\nprint('\nðŸ“Š Suma Total de Casos por GrupoTamizaje')\nsuma_total=df.groupby('GrupoTamizaje')['Casos'].sum().sort_values(ascending=False)\nplt.figure(figsize=(10,6)); bars=plt.bar(range(len(suma_total)), suma_total.values, color=colors[:len(suma_total)], alpha=0.85, edgecolor='black', linewidth=2)\nplt.xticks(range(len(suma_total)), suma_total.index, rotation=15, ha='right'); plt.ylabel('Total de Casos', fontsize=12)\nplt.title('Suma Total de Casos por GrupoTamizaje', fontsize=14, fontweight='bold', pad=15); plt.grid(axis='y', alpha=0.3)\nfor bar,val in zip(bars, suma_total.values): plt.text(bar.get_x()+bar.get_width()/2, val, f'{val:,.0f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\nplt.tight_layout(); plt.savefig('EDA_02_suma_total_casos.png', dpi=300, bbox_inches='tight'); plt.show()\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# GrÃ¡fico 3: Heatmap Tipo de Tamizaje vs Grupo\nprint('\nðŸ“Š Heatmap: Casos por Tipo de Tamizaje y Grupo')\ntop_tipos=df.groupby('DetalleTamizaje')['Casos'].sum().nlargest(10).index\ndf_top_tipos=df[df['DetalleTamizaje'].isin(top_tipos)]\npivot_tipos=df_top_tipos.pivot_table(values='Casos', index='DetalleTamizaje', columns='GrupoTamizaje', aggfunc='sum', fill_value=0)\npivot_tipos=pivot_tipos.loc[top_tipos]\nplt.figure(figsize=(10,6)); sns.heatmap(pivot_tipos.T, annot=False, cmap='YlOrRd', linewidths=1, linecolor='white', cbar_kws={'label':'Total de Casos'})\nplt.xlabel('Tipo de Tamizaje'); plt.ylabel('Grupo Tamizaje'); plt.title('Heatmap: Casos por Tipo de Tamizaje y Grupo', fontsize=14, fontweight='bold', pad=15)\nplt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.savefig('EDA_03_heatmap_tipo_grupo.png', dpi=300, bbox_inches='tight'); plt.show()\n"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# GrÃ¡fico 4: Heatmap Departamento vs Grupo\nprint('\nðŸ“Š Heatmap: Casos por Departamento y Grupo')\ntop_depts=df.groupby('Departamento')['Casos'].sum().nlargest(15).index\ndf_top_dept=df[df['Departamento'].isin(top_depts)]\npivot_dept=df_top_dept.pivot_table(values='Casos', index='Departamento', columns='GrupoTamizaje', aggfunc='sum', fill_value=0)\npivot_dept=pivot_dept.loc[top_depts]\nplt.figure(figsize=(10,6)); sns.heatmap(pivot_dept.T, annot=False, cmap='Blues', linewidths=1, linecolor='white', cbar_kws={'label':'Total de Casos'})\nplt.xlabel('Departamento'); plt.ylabel('Grupo Tamizaje'); plt.title('Heatmap: Casos por Departamento y Grupo', fontsize=14, fontweight='bold', pad=15)\nplt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.savefig('EDA_04_heatmap_departamento.png', dpi=300, bbox_inches='tight'); plt.show()\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## PreparaciÃ³n de datos: tasa de positividad"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Convertir 'Casos' a numÃ©rico si es necesario\nif df['Casos'].dtype=='object':\n    df['Casos']=pd.to_numeric(df['Casos'].astype(str).str.replace(',','').str.replace(' ',''), errors='coerce').fillna(0)\n# Separar TOTAL y POSITIVOS\ndf_total=df[df['GrupoTamizaje'].str.contains('TOTAL', case=False, na=False)].copy()\ndf_pos=df[df['GrupoTamizaje'].str.contains('POSITIVOS', case=False, na=False)].copy()\n# Renombrar y unir\ndf_total=df_total.rename(columns={'Casos':'Total'}).drop(columns=['GrupoTamizaje'])\ndf_pos=df_pos.rename(columns={'Casos':'Positivos'}).drop(columns=['GrupoTamizaje'])\nkeys=['Anio','NroMes','ubigeo','Departamento','Provincia','Distrito','Sexo','Etapa','DetalleTamizaje']\ndf_pivot=df_total.merge(df_pos[keys+['Positivos']], on=keys, how='left')\ndf_pivot['Positivos']=df_pivot['Positivos'].fillna(0)\ndf_pivot['Tasa_Positividad']=np.where(df_pivot['Total']>0,(df_pivot['Positivos']/df_pivot['Total'])*100,0)\ndf_pivot=df_pivot[df_pivot['Total']>0].copy()\nprint('Filas pivot:', len(df_pivot), ' â€” Tasa promedio:', round(df_pivot['Tasa_Positividad'].mean(),2),'%')\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## Limpieza de datos"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["before=len(df_pivot); before_avg=df_pivot['Tasa_Positividad'].mean()\ndf_clean=df_pivot[df_pivot['Tasa_Positividad']<=100].copy()\nafter=len(df_clean); after_avg=df_clean['Tasa_Positividad'].mean()\nprint(f'Eliminados {before-after} | Antes: {before} (avg {before_avg:.2f}%) | DespuÃ©s: {after} (avg {after_avg:.2f}%)')\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## IngenierÃ­a de caracterÃ­sticas (one-hot encoding)"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_encoded=pd.get_dummies(df_clean, columns=['Departamento','Sexo','DetalleTamizaje','Etapa'], dtype=int)\n# Eliminar columnas menos Ãºtiles\ndf_encoded=df_encoded.drop(columns=['Provincia','Distrito'])\ny=df_encoded['Tasa_Positividad']\nX=df_encoded.drop(columns=['Tasa_Positividad','Total','Positivos'])\nprint('X:', X.shape, ' y:', y.shape)\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## Balanceo de datos (submuestreo ceros + KNN oversampling positivos)"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import NearestNeighbors\nzero=(y==0)\nX_zero,y_zero=X[zero],y[zero]; X_non_zero,y_non_zero=X[~zero],y[~zero]\nprint('Original -> ceros:', len(y_zero), '| positivos:', len(y_non_zero))\nzero_ratio=0.3; oversample_factor=2\nn_zeros_keep=int(len(y_non_zero)/(1-zero_ratio)*zero_ratio)\nif n_zeros_keep < len(y_zero):\n    idx=np.random.choice(len(y_zero), n_zeros_keep, replace=False); X_zero_s=X_zero.iloc[idx]; y_zero_s=y_zero.iloc[idx]\nelse:\n    X_zero_s,y_zero_s=X_zero,y_zero\nprint('Ceros conservados:', len(y_zero_s))\nX_syn=[]; y_syn=[]\nif len(X_non_zero)>1:\n    k=min(5, len(X_non_zero)-1); knn=NearestNeighbors(n_neighbors=k+1).fit(X_non_zero)\n    n_syn=int(len(X_non_zero)*(oversample_factor-1)); np.random.seed(42)\n    for _ in range(n_syn):\n        i=np.random.randint(0,len(X_non_zero)); x=X_non_zero.iloc[i].values; yv=y_non_zero.iloc[i]\n        neigh=knn.kneighbors([x], return_distance=False)[0]; j=np.random.choice(neigh[1:])\n        a=np.random.random(); xn=X_non_zero.iloc[j].values; yn=y_non_zero.iloc[j]\n        X_syn.append(x+a*(xn-x)); y_syn.append(yv+a*(yn-yv))\nXb=pd.concat([X_zero_s, X_non_zero, pd.DataFrame(X_syn, columns=X.columns)], ignore_index=True)\nyb=pd.concat([y_zero_s, y_non_zero, pd.Series(y_syn, name='Tasa_Positividad')], ignore_index=True)\nprint('Balanceado -> ceros:', (yb==0).sum(), '| positivos:', (yb>0).sum())\n# Guardar y grÃ¡fico comparativo\ndf_balanced=Xb.copy(); df_balanced['Tasa_Positividad']=yb.values\ndf_balanced.to_csv('dataset_balanceado.csv', index=False, encoding='utf-8-sig')\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nax[0].bar(['Ceros','Positivos'], [(yb==0).sum(), (yb>0).sum()], color=['coral','lightblue'], edgecolor='black'); ax[0].set_title('Dataset Balanceado'); ax[0].grid(axis='y', alpha=0.3)\nax[1].bar(['Ceros','Positivos'], [(y==0).sum(), (y>0).sum()], color=['lightgreen','lightblue'], edgecolor='black'); ax[1].set_title('Dataset Original'); ax[1].grid(axis='y', alpha=0.3)\nplt.tight_layout(); plt.savefig('DATA_PREP_balanceo_comparacion.png', dpi=300, bbox_inches='tight'); plt.show()\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## Modelo: split, entrenamiento"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nMODEL_TYPE='gradient_boosting'  # 'random_forest' o 'gradient_boosting'\nX_train,X_test,y_train,y_test=train_test_split(Xb,yb,test_size=0.2,random_state=42)\nif MODEL_TYPE=='random_forest':\n    model=RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, oob_score=True)\nelse:\n    model=GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\nmodel.fit(X_train,y_train)\ny_pred_tr=model.predict(X_train); y_pred_te=model.predict(X_test)\nr2_tr=r2_score(y_train,y_pred_tr); r2_te=r2_score(y_test,y_pred_te)\nmae_tr=mean_absolute_error(y_train,y_pred_tr); mae_te=mean_absolute_error(y_test,y_pred_te)\nrmse_tr=np.sqrt(mean_squared_error(y_train,y_pred_tr)); rmse_te=np.sqrt(mean_squared_error(y_test,y_pred_te))\nprint(f'Train -> R2:{r2_tr:.4f} MAE:{mae_tr:.4f}% RMSE:{rmse_tr:.4f}%')\nprint(f'Test  -> R2:{r2_te:.4f} MAE:{mae_te:.4f}% RMSE:{rmse_te:.4f}%')\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## EvaluaciÃ³n y grÃ¡ficos"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\nos.makedirs('docs', exist_ok=True)\nfig,ax=plt.subplots(1,2,figsize=(16,6))\nax[0].scatter(y_train,y_pred_tr,alpha=0.5,s=10,color='steelblue'); ax[0].plot([y_train.min(),y_train.max()],[y_train.min(),y_train.max()],'r--',lw=2); ax[0].set_title(f'Train (RÂ²={r2_tr:.3f})'); ax[0].grid(alpha=0.3); ax[0].set_xlabel('Reales'); ax[0].set_ylabel('Pred')\nax[1].scatter(y_test,y_pred_te,alpha=0.5,s=10,color='darkorange'); ax[1].plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()],'r--',lw=2); ax[1].set_title(f'Test (RÂ²={r2_te:.3f})'); ax[1].grid(alpha=0.3); ax[1].set_xlabel('Reales'); ax[1].set_ylabel('Pred')\nplt.tight_layout(); plt.savefig('docs/evaluation_actual_vs_predicted.png', dpi=300, bbox_inches='tight'); plt.show()\nimp=getattr(model,'feature_importances_', None)\nif imp is not None:\n    importances=pd.DataFrame({'Feature':Xb.columns,'Importance':imp}).sort_values('Importance',ascending=False).head(15)\n    plt.figure(figsize=(10,8)); plt.barh(range(len(importances)), importances['Importance'], color='darkorange'); plt.yticks(range(len(importances)), importances['Feature']); plt.gca().invert_yaxis(); plt.tight_layout(); plt.savefig('docs/evaluation_feature_importance.png', dpi=300, bbox_inches='tight'); plt.show()\nelse:\n    print('El modelo no expone feature_importances_')\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## Curva de aprendizaje (Gradient Boosting)"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingRegressor\nif isinstance(model, GradientBoostingRegressor):\n    plt.figure(figsize=(12,5))\n    plt.subplot(1,2,1)\n    if hasattr(model,'train_score_'):\n        plt.plot(model.train_score_, color='steelblue'); plt.title('Score de Entrenamiento'); plt.grid(alpha=0.3)\n    else:\n        plt.text(0.5,0.5,'train_score_ no disponible', ha='center')\n    plt.subplot(1,2,2)\n    cum=np.cumsum(sorted(model.feature_importances_, reverse=True))\n    plt.plot(cum, color='darkorange'); plt.axhline(y=0.95, color='r', ls='--'); plt.title('Importancia Acumulada'); plt.grid(alpha=0.3)\n    plt.tight_layout(); plt.savefig('EVALUATION_learning_curve_GB.png', dpi=300, bbox_inches='tight'); plt.show()\nelse:\n    print('Aplica sÃ³lo a Gradient Boosting')\n"]},
    {"cell_type": "markdown", "metadata": {}, "source": ["## Guardar modelo"]},
    {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pickle\nwith open('trained_model.pkl','wb') as f:\n    pickle.dump({'model':model,'feature_names':list(Xb.columns),'model_type':MODEL_TYPE,'metrics':{'train':{'R2':r2_tr,'MAE':mae_tr,'RMSE':rmse_tr},'test':{'R2':r2_te,'MAE':mae_te,'RMSE':rmse_te}}}, f)\nprint('Modelo guardado en trained_model.pkl')\n"]}
  ],
  "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}},
  "nbformat": 4,
  "nbformat_minor": 5
}
