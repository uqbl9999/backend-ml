# Gu√≠a de IA Explicable (XAI) con Perplexity

## üìñ Introducci√≥n

La funcionalidad de **Explainable AI (XAI)** del sistema proporciona explicaciones claras y accionables sobre las predicciones del modelo de riesgo de salud mental. Utilizando **Perplexity AI** con modelos Llama 3.1 Sonar, el sistema genera contexto situacional, acciones recomendadas y factores clave para cada predicci√≥n.

## üéØ Objetivo

El m√≥dulo XAI tiene como objetivos:

1. **Transparencia**: Que los usuarios comprendan por qu√© se obtiene cierto nivel de riesgo
2. **Acci√≥n**: Proporcionar recomendaciones espec√≠ficas y aplicables
3. **Confianza**: Aumentar la confianza en las predicciones del modelo mediante explicaciones
4. **UI-friendly**: Generar explicaciones concisas que se integren perfectamente en interfaces de usuario

## üîß Configuraci√≥n

### Requisitos

- API Key de Perplexity (obt√©n una en [perplexity.ai/settings/api](https://www.perplexity.ai/settings/api))
- Python 3.8+
- Paquete `requests` (incluido en requirements.txt)

### Configurar API Key

**Opci√≥n 1: Variable de entorno**

```bash
# Linux/Mac
export PERPLEXITY_API_KEY="pplx-..."

# Windows CMD
set PERPLEXITY_API_KEY=pplx-...

# Windows PowerShell
$env:PERPLEXITY_API_KEY="pplx-..."
```

**Opci√≥n 2: Archivo .env**

1. Copia `.env.example` a `.env`
2. Edita `.env` y agrega tu API key:
   ```
   PERPLEXITY_API_KEY=pplx-your-actual-key-here
   ```

## üöÄ Uso

### Endpoint Principal

```bash
POST /predict/explain
```

### Ejemplo de Request

```bash
curl -X POST "http://localhost:8000/predict/explain" \
  -H "Content-Type: application/json" \
  -d '{
    "NroMes": 1,
    "Departamento": "ANCASH",
    "Provincia": "AIJA",
    "Sexo": "F",
    "Etapa": "< 1",
    "DetalleTamizaje": "SINDROME Y/O TRASTORNO PSICOTICO"
  }'
```

### Ejemplo de Response

```json
{
  "tasa_positividad_predicha": 24.02,
  "interpretacion": "Riesgo Muy Alto - Intervenci√≥n urgente requerida",
  "input_data": {
    "NroMes": 1,
    "Departamento": "ANCASH",
    "Provincia": "AIJA",
    "Sexo": "F",
    "Etapa": "< 1",
    "DetalleTamizaje": "SINDROME Y/O TRASTORNO PSICOTICO",
    "ubigeo": 20201
  },
  "explicacion": {
    "contexto_situacional": "La tasa se encuentra en un rango moderado respecto a la media hist√≥rica. Se recomienda fortalecer la detecci√≥n temprana y reforzar los protocolos de derivaci√≥n.",
    "acciones": [
      "Reforzar acciones preventivas y seguimiento",
      "Monitorear indicadores cr√≠ticos semanalmente",
      "Coordinar intervenci√≥n con equipos territoriales"
    ],
    "factores_clave": [
      "Combinaci√≥n espec√≠fica de ubicaci√≥n geogr√°fica y grupo etario",
      "Mes del a√±o y tipo de tamizaje espec√≠fico"
    ]
  }
}
```

## üìä Estructura de la Explicaci√≥n

### 1. Contexto Situacional

- **Qu√© es**: Una frase corta (m√°ximo 25 palabras) que explica el nivel de riesgo
- **Prop√≥sito**: Dar contexto sobre por qu√© la tasa est√° en ese rango
- **Ejemplo**: "La tasa se encuentra en un rango moderado respecto a la media hist√≥rica..."

### 2. Acciones Recomendadas

- **Qu√© es**: Array con 3 acciones preventivas concretas
- **Formato**: Cada acci√≥n tiene m√°ximo 10 palabras
- **Prop√≥sito**: Proporcionar pasos accionables espec√≠ficos para el contexto
- **Ejemplo**:
  - "Reforzar acciones preventivas y seguimiento"
  - "Monitorear indicadores cr√≠ticos semanalmente"
  - "Coordinar intervenci√≥n con equipos territoriales"

### 3. Factores Clave

- **Qu√© es**: Array con 2-3 factores principales que influyen en la predicci√≥n
- **Formato**: Cada factor tiene m√°ximo 8 palabras
- **Prop√≥sito**: Identificar qu√© caracter√≠sticas tienen mayor impacto
- **Ejemplo**:
  - "Combinaci√≥n espec√≠fica de ubicaci√≥n geogr√°fica y grupo etario"
  - "Mes del a√±o y tipo de tamizaje espec√≠fico"

## üîç C√≥mo Funciona

### Flujo de Proceso

```
1. Usuario env√≠a request ‚Üí /predict/explain
                ‚Üì
2. Sistema valida entrada y calcula ubigeo
                ‚Üì
3. Modelo ML genera predicci√≥n
                ‚Üì
4. XAI Service construye prompt contextual
                ‚Üì
5. Perplexity AI analiza y genera explicaci√≥n
                ‚Üì
6. Sistema combina predicci√≥n + explicaci√≥n
                ‚Üì
7. Response con datos completos al usuario
```

### Prompt Engineering

El servicio XAI construye un prompt espec√≠fico que incluye:

- Contexto geogr√°fico (Departamento, Provincia)
- Caracter√≠sticas demogr√°ficas (Sexo, Edad)
- Informaci√≥n temporal (Mes)
- Tipo de tamizaje
- Resultado de la predicci√≥n
- Nivel de riesgo interpretado

Perplexity AI recibe instrucciones para generar:
- Explicaciones extremadamente concisas
- Acciones espec√≠ficas al contexto
- Formato JSON estructurado

## üí∞ Consideraciones de Costo

### Modelo Utilizado

- **Por defecto**: `sonar` (basado en Llama 3.3 70B)
- **Motivo**: Ligero, econ√≥mico y con acceso a informaci√≥n actualizada
- **Tokens promedio**: ~500 tokens por explicaci√≥n
- **Lanzamiento**: Febrero 2025 (√∫ltima generaci√≥n)

### Estimaci√≥n de Costos

A precio actual de Perplexity AI:
- **Costo por 1M tokens**: Aproximadamente $1 USD
- **Costo por explicaci√≥n**: ~$0.0005 (medio centavo)
- **Muy econ√≥mico**: M√°s barato que GPT-4o-mini

### Optimizaci√≥n

Para reducir costos a√∫n m√°s:
1. Implementar cach√© de explicaciones similares
2. Reducir max_tokens si las explicaciones son muy largas
3. Usar temperature m√°s baja (menos creatividad = menos tokens)

## üõ°Ô∏è Manejo de Errores

### Escenarios de Fallback

El servicio XAI incluye manejo robusto de errores:

1. **API Key no configurada**: Retorna error 503 indicando configuraci√≥n faltante
2. **Error de Perplexity**: Retorna explicaci√≥n gen√©rica predeterminada
3. **Timeout**: Explicaci√≥n de fallback sin interrumpir el servicio

### Explicaci√≥n de Fallback

Si Perplexity AI falla, el sistema retorna:

```json
{
  "contexto_situacional": "No se pudo generar la explicaci√≥n autom√°tica.",
  "acciones": [
    "Reforzar acciones preventivas y seguimiento",
    "Monitorear indicadores cr√≠ticos semanalmente",
    "Coordinar intervenci√≥n con equipos territoriales"
  ],
  "factores_clave": [
    "Combinaci√≥n de factores demogr√°ficos y geogr√°ficos",
    "Patr√≥n estacional y tipo de tamizaje"
  ]
}
```

## üî¨ Personalizaci√≥n

### Cambiar el Modelo

Puedes usar un modelo diferente editando `xai_service.py`:

```python
# Modelos disponibles en Perplexity (2025):
# - sonar (ligero, econ√≥mico, recomendado para producci√≥n)
# - sonar-pro (avanzado, mejor calidad con grounding mejorado)

explanation = xai_service.generate_explanation(
    params=params,
    prediction=prediction,
    interpretation=interpretation,
    model="sonar-pro"  # Modelo m√°s potente
)
```

### Ajustar Temperature

```python
# M√°s determin√≠stico (menos creatividad)
explanation = xai_service.generate_explanation(
    params=params,
    prediction=prediction,
    interpretation=interpretation,
    temperature=0.3  # M√°s consistente
)

# M√°s creativo (m√°s variedad)
explanation = xai_service.generate_explanation(
    params=params,
    prediction=prediction,
    interpretation=interpretation,
    temperature=1.0  # M√°s variado
)
```

## üìù Mejores Pr√°cticas

### Uso en Producci√≥n

1. **Monitorear costos**: Revisa uso en Perplexity dashboard
2. **Implementar rate limiting**: Evita sobrecostos por uso excesivo
3. **Cach√© inteligente**: Guarda explicaciones para par√°metros similares
4. **Logging**: Registra todas las llamadas para an√°lisis posterior
5. **Validaci√≥n m√©dica**: Revisa con expertos la calidad de las explicaciones

### Uso Responsable

1. **Disclaimer**: Las explicaciones son orientativas, no diagn√≥sticos
2. **Revisi√≥n humana**: Expertos en salud deben validar recomendaciones
3. **Privacidad**: No incluyas informaci√≥n sensible en los prompts
4. **Transparencia**: Indica claramente que las explicaciones son generadas por IA

## üß™ Testing

### Test Manual

```bash
# Con API key configurada
curl -X POST "http://localhost:8000/predict/explain" \
  -H "Content-Type: application/json" \
  -d '{
    "NroMes": 6,
    "Departamento": "LIMA",
    "Provincia": "LIMA",
    "Sexo": "M",
    "Etapa": "18 - 24",
    "DetalleTamizaje": "TRASTORNO DEPRESIVO"
  }'
```

### Verificar Configuraci√≥n

```bash
# Verificar que la API key est√° configurada (Linux/Mac)
echo $PERPLEXITY_API_KEY

# Windows CMD
echo %PERPLEXITY_API_KEY%

# Windows PowerShell
echo $env:PERPLEXITY_API_KEY
```

## ‚ùì Troubleshooting

### Error: "XAI service not available"

**Causa**: Variable de entorno `PERPLEXITY_API_KEY` no configurada

**Soluci√≥n**:
```bash
export PERPLEXITY_API_KEY="pplx-..."
# Reinicia la API
```

### Error: "Authentication failed"

**Causa**: API key inv√°lida o sin cr√©ditos

**Soluci√≥n**:
1. Verifica tu API key en Perplexity dashboard
2. Confirma que tienes cr√©ditos disponibles
3. Regenera la API key si es necesario

### Explicaciones gen√©ricas

**Causa**: Prompts no suficientemente espec√≠ficos

**Soluci√≥n**:
- Revisa y ajusta los prompts en `xai_service.py`
- Reduce la temperature para m√°s consistencia
- Considera usar un modelo m√°s potente (llama-3.1-sonar-large)

### Error: Respuesta no es JSON v√°lido

**Causa**: Perplexity a veces incluye texto markdown alrededor del JSON

**Soluci√≥n**:
- El servicio ya incluye limpieza autom√°tica de markdown
- Si persiste, revisa el contenido raw en los logs

## üîó Referencias

- [Perplexity API Documentation](https://docs.perplexity.ai/)
- [Perplexity API Pricing](https://www.perplexity.ai/settings/api)
- [Best Practices for Prompt Engineering](https://docs.perplexity.ai/guides/prompting)

## üí° Ventajas de Perplexity AI

1. **Acceso a informaci√≥n actualizada**: Modelos "online" con b√∫squeda web
2. **Costo competitivo**: M√°s econ√≥mico que alternativas similares
3. **Modelos Llama 3.1**: Modelos de c√≥digo abierto de alta calidad
4. **Sin censura excesiva**: Mejor para temas de salud mental
5. **API REST simple**: Uso directo con requests, sin dependencias pesadas

## üìß Soporte

Para preguntas o problemas con XAI:
1. Revisa esta gu√≠a completa
2. Verifica los logs de la API
3. Consulta la documentaci√≥n de Perplexity
4. Abre un issue en el repositorio del proyecto
